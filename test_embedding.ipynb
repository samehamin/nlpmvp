{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samehstudy/sourcecode/nlpmvp/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default-b7cf248e1f7aa5f0\n",
      "Reusing dataset csv (/Users/samehstudy/.cache/huggingface/datasets/csv/default-b7cf248e1f7aa5f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "100%|██████████| 2/2 [00:00<00:00, 819.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"csv\", data_files=\"Data/user_defined_utterances.csv\")\n",
    "dataset = load_dataset(\"csv\", data_files={\"train\": [\"Data/user_train.csv\"], \"valid\": \"Data/user_test.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nickprock/xlm-roberta-base-banking77-classification were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at nickprock/xlm-roberta-base-banking77-classification and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_ckpt = 'nickprock/xlm-roberta-base-banking77-classification'\n",
    "# model_ckpt = 'miguelvictor/python-gpt2-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    # Extract the token embeddings\n",
    "    token_embeddings = model_output[0]\n",
    "    # Compute the attention mask\n",
    "    input_mask_expanded = (attention_mask\n",
    "        .unsqueeze(-1)\n",
    "        .expand(token_embeddings.size())\n",
    "        .float())\n",
    "    # Sum the embeddings, but ignore masked tokens\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    # Return the average as a single vector\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(examples):\n",
    "    inputs = tokenizer(examples[\"text\"], padding=True, truncation=True,\n",
    "                        max_length=128, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**inputs)\n",
    "    pooled_embeds = mean_pooling(model_output, inputs[\"attention_mask\"])\n",
    "    return {\"embedding\": pooled_embeds.cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.85ba/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.73ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "embs_train = dataset[\"train\"].map(embed_text, batched=True, batch_size=16)\n",
    "embs_valid = dataset[\"valid\"].map(embed_text, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 880.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category', 'embedding'],\n",
       "    num_rows: 79\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_train.add_faiss_index(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'category', 'embedding'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "i, k = 0, 3 # Select the first query and 3 nearest neighbors\n",
    "rn, nl = \"\\r\\n\\r\\n\", \"\\n\" # Used to remove newlines in text for compact display\n",
    "\n",
    "query =  np.array(embs_valid[i][\"embedding\"], dtype=np.float32)\n",
    "scores, samples = embs_train.get_nearest_examples(\"embedding\", query, k=k)\n",
    "\n",
    "# print(f\"QUERY LABELS: {embs_valid[i]['category']}\")\n",
    "# print(f\"QUERY TEXT:\\n{embs_valid[i]['text'][:200].replace(rn, nl)} [...]\\n\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"Retrieved documents:\")\n",
    "# for score, label, text in zip(scores, samples[\"category\"], samples[\"text\"]):\n",
    "#     print(\"=\"*50)\n",
    "#     print(f\"TEXT:\\n{text[:200].replace(rn, nl)} [...]\")\n",
    "#     print(f\"SCORE: {score:.2f}\")\n",
    "#     print(f\"LABELS: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_sample_preds(sample, m):\n",
    "    return (np.sum(sample[\"label_ids\"], axis=0) >= m).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_k_m(ds_train, valid_queries, valid_labels, max_k=17):\n",
    "#     max_k = min(len(ds_train), max_k)\n",
    "#     perf_micro = np.zeros((max_k, max_k))\n",
    "#     perf_macro = np.zeros((max_k, max_k))\n",
    "#     for k in range(1, max_k):\n",
    "#         for m in range(1, k + 1):\n",
    "#             samples = ds_train.get_nearest_examples_batch(\"embedding\",\n",
    "#             valid_queries,\n",
    "#             k=k)\n",
    "#             y_pred = np.array([get_sample_preds(s, m) for s in samples])\n",
    "#             clf_report = classification_report(valid_labels, y_pred,\n",
    "#             target_names=mlb.classes_, zero_division=0, output_dict=True)\n",
    "#         perf_micro[k, m] = clf_report[\"micro avg\"][\"f1-score\"]\n",
    "#         perf_macro[k, m] = clf_report[\"macro avg\"][\"f1-score\"]\n",
    "# return perf_micro, perf_macro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74f9448b2f12de8dac36d2fae94f2a077fcea3ddeb8da091f1cbe52d9ba4a671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
